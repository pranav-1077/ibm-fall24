{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMkG77Ibd9xH"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch torchvision Pillow tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD IN S3 BUCKET CONTENTS"
      ],
      "metadata": {
        "id": "jhnYvhWcoKkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iznSVA9tlD47",
        "outputId": "6227bb33-03ec-44c2-a3f6-27f3613c012b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/139.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/139.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade awscli"
      ],
      "metadata": {
        "id": "6A9gKnfml3xR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!aws configure"
      ],
      "metadata": {
        "id": "K4H95QckmQ1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD IN PRETRAINED BLIP MODEL"
      ],
      "metadata": {
        "id": "UL7-eGXV71Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "u6EQOtmM74vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Check if a GPU is available\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# Load the model using the GPU if available\n",
        "pipe = pipeline(\n",
        "    \"image-to-text\",\n",
        "    model=\"Gurveer05/blip-image-captioning-base-rscid-finetuned\",\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "5wQWsxb-73fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INFERENCE ON IMAGES"
      ],
      "metadata": {
        "id": "fbARWRVi79PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "from botocore.exceptions import ClientError\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_inference(pipe, bucket_name, subfolder, output_csv):\n",
        "    \"\"\"\n",
        "    Downloads .tif images from an S3 bucket, runs inference,\n",
        "    and writes the descriptions to a CSV.\n",
        "\n",
        "    Args:\n",
        "        pipe (pipeline): The pre-loaded Hugging Face pipeline for image captioning.\n",
        "        bucket_name (str): The name of the S3 bucket.\n",
        "        subfolder (str): The subfolder within the S3 bucket.\n",
        "        output_csv (str): The path to the CSV file where results will be saved.\n",
        "    \"\"\"\n",
        "    # Initialize the S3 client\n",
        "    s3_client = boto3.client('s3')\n",
        "\n",
        "    continuation_token = None\n",
        "    results = []\n",
        "\n",
        "    print(f\"Fetching list of .tif files from '{bucket_name}/{subfolder}'...\")\n",
        "    all_keys = []\n",
        "\n",
        "    try:\n",
        "        # Step 1: List all .tif files with pagination\n",
        "        while True:\n",
        "            if continuation_token:\n",
        "                response = s3_client.list_objects_v2(\n",
        "                    Bucket=bucket_name,\n",
        "                    Prefix=subfolder,\n",
        "                    ContinuationToken=continuation_token\n",
        "                )\n",
        "            else:\n",
        "                response = s3_client.list_objects_v2(\n",
        "                    Bucket=bucket_name,\n",
        "                    Prefix=subfolder\n",
        "                )\n",
        "\n",
        "            # Check if any objects were found\n",
        "            if 'Contents' not in response:\n",
        "                print(\"No images found in the specified subfolder.\")\n",
        "                break\n",
        "\n",
        "            # Add .tif files to the list\n",
        "            all_keys.extend([content['Key'] for content in response['Contents'] if content['Key'].endswith('.tif')])\n",
        "\n",
        "            # Check if there are more objects to fetch\n",
        "            if response.get('IsTruncated'):\n",
        "                continuation_token = response['NextContinuationToken']\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    except ClientError as e:\n",
        "        print(f\"Error accessing bucket: {e}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Total .tif images found: {len(all_keys)}\")\n",
        "\n",
        "    # Step 2: Download, convert, run inference, and store results\n",
        "    for key in tqdm(all_keys, desc=\"Processing images\", unit=\"image\"):\n",
        "        try:\n",
        "            # Download the image directly from S3\n",
        "            img_response = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
        "            image_data = img_response['Body'].read()\n",
        "\n",
        "            # Open the image using PIL and convert to RGB if necessary\n",
        "            with Image.open(BytesIO(image_data)) as image:\n",
        "                image = image.convert(\"RGB\")\n",
        "\n",
        "                # Run inference using the BLIP model\n",
        "                caption = pipe(image)[0]['generated_text']\n",
        "\n",
        "                # Append the result to the list\n",
        "                results.append({'image_name': key, 'description': caption})\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {key}: {e}\")\n",
        "\n",
        "    # Step 3: Write the results to a CSV file\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Descriptions saved to {output_csv}\")\n"
      ],
      "metadata": {
        "id": "6VLQ7n0lm--S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\n",
        "    pipe=pipe,\n",
        "    bucket_name='_',\n",
        "    subfolder='_',\n",
        "    output_csv='/content/image_descriptions.csv'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axit0JGx8vB8",
        "outputId": "c933bbae-8b23-4502-a1f8-68d9aabc8ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching list of .tif files from 'ibm-rsc/tif_patches'...\n",
            "Total .tif images found: 12006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing images:   0%|          | 0/12006 [00:00<?, ?image/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Processing images:   0%|          | 10/12006 [00:06<1:30:07,  2.22image/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Processing images:  73%|███████▎  | 8732/12006 [54:22<13:39,  4.00image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing tif_patches/N-33-60-D-c-4-2_4096_1024.tif: -2\n",
            "Error processing tif_patches/N-33-60-D-c-4-2_4096_1536.tif: -2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 12006/12006 [1:13:45<00:00,  2.71image/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptions saved to /content/image_descriptions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}